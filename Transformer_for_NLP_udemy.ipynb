{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_for_NLP_udemy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonVillanueva/CoLab/blob/master/Transformer_for_NLP_udemy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9JJ7FBw84tG"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbcvtPlp3YWu"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6o_cpZz3y_-"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQN8jwx48_yU"
      },
      "source": [
        "# Stage 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPlOT-2mlw0r"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCD9jwXsLwS_"
      },
      "source": [
        "We import files from our personal google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQpbl1pXCR0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8415b980-bf21-42fa-9a6d-425817c7b6ee"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Or0sLV5b8t"
      },
      "source": [
        "with open(\"/content/drive/My Drive/projects/transformer/data/europarl-v7.fr-en.en\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    europarl_en = f.read()\n",
        "with open(\"/content/drive/My Drive/projects/transformer/data/europarl-v7.fr-en.fr\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    europarl_fr = f.read()\n",
        "with open(\"/content/drive/My Drive/projects/transformer/data/nonbreaking_prefix.en\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    non_breaking_prefix_en = f.read()\n",
        "with open(\"/content/drive/My Drive/projects/transformer/data/nonbreaking_prefix.fr\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    non_breaking_prefix_fr = f.read()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEFw0D2vP_Dl"
      },
      "source": [
        "## Cleaning data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwIBeGXn7LIJ"
      },
      "source": [
        "Getting the non_breaking_prefixes as a clean list of words with a point at the end so it is easier to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_TeuktU40Cb"
      },
      "source": [
        "non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n",
        "non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]\n",
        "non_breaking_prefix_fr = non_breaking_prefix_fr.split(\"\\n\")\n",
        "non_breaking_prefix_fr = [' ' + pref + '.' for pref in non_breaking_prefix_fr]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9x4mZfKMaxD"
      },
      "source": [
        "We will need each word and other symbol that we want to keep to be in lower case and separated by spaces so we can \"tokenize\" them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg-8LLK-WdFp"
      },
      "source": [
        "corpus_en = europarl_en\n",
        "# Add $$$ after non ending sentence points\n",
        "for prefix in non_breaking_prefix_en:\n",
        "    corpus_en = corpus_en.replace(prefix, prefix + '$$$')\n",
        "corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_en)\n",
        "# Remove $$$ markers\n",
        "corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
        "# Clear multiple spaces\n",
        "corpus_en = re.sub(r\"  +\", \" \", corpus_en)\n",
        "corpus_en = corpus_en.split('\\n')\n",
        "\n",
        "corpus_fr = europarl_fr\n",
        "for prefix in non_breaking_prefix_fr:\n",
        "    corpus_fr = corpus_fr.replace(prefix, prefix + '$$$')\n",
        "corpus_fr = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_fr)\n",
        "corpus_fr = re.sub(r\".\\$\\$\\$\", '', corpus_fr)\n",
        "corpus_fr = re.sub(r\"  +\", \" \", corpus_fr)\n",
        "corpus_fr = corpus_fr.split('\\n')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Y9v8-Tozl2"
      },
      "source": [
        "## Tokenizing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5YXanmOd_xK"
      },
      "source": [
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_en, target_vocab_size=2**13)\n",
        "tokenizer_fr = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_fr, target_vocab_size=2**13)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftIbPzIwCtwL"
      },
      "source": [
        "VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2 # = 8190\n",
        "VOCAB_SIZE_FR = tokenizer_fr.vocab_size + 2 # = 8171"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPFe2YJDC9jw"
      },
      "source": [
        "inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]\n",
        "          for sentence in corpus_en]\n",
        "outputs = [[VOCAB_SIZE_FR-2] + tokenizer_fr.encode(sentence) + [VOCAB_SIZE_FR-1]\n",
        "           for sentence in corpus_fr]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG6AlcFMpC5C"
      },
      "source": [
        "## Remove too long sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6CD6PLGyQWy"
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "idx_to_remove = [count for count, sent in enumerate(inputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]\n",
        "idx_to_remove = [count for count, sent in enumerate(outputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypm8h5aZQTZ1"
      },
      "source": [
        "## Inputs/outputs creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FP0WPsdM8hl"
      },
      "source": [
        "As we train with batches, we need each input to have the same length. We pad with the appropriate token, and we will make sure this padding token doesn't interfere with our training later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvDfLDWUONlE"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                       value=0,\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LENGTH)\n",
        "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
        "                                                        value=0,\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LENGTH)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFxMp3TOIYff"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycT0YqydRcUd"
      },
      "source": [
        "# Stage 3: Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SBoH8G4XyR9"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G9C3ucmJ86I"
      },
      "source": [
        "Positional encoding formulae:\n",
        "\n",
        "$PE_{(pos,2i)} =\\sin(pos/10000^{2i/dmodel})$\n",
        "\n",
        "$PE_{(pos,2i+1)} =\\cos(pos/10000^{2i/dmodel})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2wc6sYlX0dr"
      },
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
        "        return pos * angles\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_length = inputs.shape.as_list()[-2]\n",
        "        d_model = inputs.shape.as_list()[-1]\n",
        "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
        "                                 np.arange(d_model)[np.newaxis, :],\n",
        "                                 d_model)\n",
        "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "        pos_encoding = angles[np.newaxis, ...]\n",
        "        return inputs + tf.cast(pos_encoding, tf.float32)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcw8YIQqRhOJ"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sffhwwvX-wj"
      },
      "source": [
        "### Attention computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VBuW6lESLDX"
      },
      "source": [
        "$Attention(Q, K, V ) = \\text{softmax}\\left(\\dfrac{QK^T}{\\sqrt{d_k}}\\right)V $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEoCNJURbrT"
      },
      "source": [
        "def scaled_dot_product_attention(queries, keys, values, mask):\n",
        "    product = tf.matmul(queries, keys, transpose_b=True)\n",
        "    \n",
        "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
        "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
        "    \n",
        "    if mask is not None:\n",
        "        scaled_product += (mask * -1e9)\n",
        "    \n",
        "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
        "    \n",
        "    return attention"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MjtvXrfYEx7"
      },
      "source": [
        "### Multi-head attention sublayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvq4I9uTX5p7"
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "    \n",
        "    def __init__(self, nb_proj):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.nb_proj = nb_proj\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        assert self.d_model % self.nb_proj == 0\n",
        "        \n",
        "        self.d_proj = self.d_model // self.nb_proj\n",
        "        \n",
        "        self.query_lin = layers.Dense(units=self.d_model)\n",
        "        self.key_lin = layers.Dense(units=self.d_model)\n",
        "        self.value_lin = layers.Dense(units=self.d_model)\n",
        "        \n",
        "        self.final_lin = layers.Dense(units=self.d_model)\n",
        "        \n",
        "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n",
        "        shape = (batch_size,\n",
        "                 -1,\n",
        "                 self.nb_proj,\n",
        "                 self.d_proj)\n",
        "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n",
        "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_length, d_proj)\n",
        "    \n",
        "    def call(self, queries, keys, values, mask):\n",
        "        batch_size = tf.shape(queries)[0]\n",
        "        \n",
        "        queries = self.query_lin(queries)\n",
        "        keys = self.key_lin(keys)\n",
        "        values = self.value_lin(values)\n",
        "        \n",
        "        queries = self.split_proj(queries, batch_size)\n",
        "        keys = self.split_proj(keys, batch_size)\n",
        "        values = self.split_proj(values, batch_size)\n",
        "        \n",
        "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
        "        \n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        \n",
        "        concat_attention = tf.reshape(attention,\n",
        "                                      shape=(batch_size, -1, self.d_model))\n",
        "        \n",
        "        outputs = self.final_lin(concat_attention)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiyuHe1OeT5N"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV0ZMH7KT_KZ"
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "    \n",
        "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.nb_proj = nb_proj\n",
        "        self.dropout_rate = dropout_rate\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        \n",
        "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
        "        self.dense_2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "    def call(self, inputs, mask, training):\n",
        "        attention = self.multi_head_attention(inputs,\n",
        "                                              inputs,\n",
        "                                              inputs,\n",
        "                                              mask)\n",
        "        attention = self.dropout_1(attention, training=training)\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "        \n",
        "        outputs = self.dense_1(attention)\n",
        "        outputs = self.dense_2(outputs)\n",
        "        outputs = self.dropout_2(outputs, training=training)\n",
        "        outputs = self.norm_2(outputs + attention)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-P92KeZih60"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.nb_layers = nb_layers\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        nb_proj,\n",
        "                                        dropout_rate) \n",
        "                           for _ in range(nb_layers)]\n",
        "    \n",
        "    def call(self, inputs, mask, training):\n",
        "        outputs = self.embedding(inputs)\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        \n",
        "        for i in range(self.nb_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DthraBEwuvl"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZWZyFBnwy8u"
      },
      "source": [
        "class DecoderLayer(layers.Layer):\n",
        "    \n",
        "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.nb_proj = nb_proj\n",
        "        self.dropout_rate = dropout_rate\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        \n",
        "        # Self multi head attention\n",
        "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        # Multi head attention combined with encoder output\n",
        "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        # Feed foward\n",
        "        self.dense_1 = layers.Dense(units=self.FFN_units,\n",
        "                                    activation=\"relu\")\n",
        "        self.dense_2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_3 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "        attention = self.multi_head_attention_1(inputs,\n",
        "                                                inputs,\n",
        "                                                inputs,\n",
        "                                                mask_1)\n",
        "        attention = self.dropout_1(attention, training)\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "        \n",
        "        attention_2 = self.multi_head_attention_2(attention,\n",
        "                                                  enc_outputs,\n",
        "                                                  enc_outputs,\n",
        "                                                  mask_2)\n",
        "        attention_2 = self.dropout_2(attention_2, training)\n",
        "        attention_2 = self.norm_2(attention_2 + attention)\n",
        "        \n",
        "        outputs = self.dense_1(attention_2)\n",
        "        outputs = self.dense_2(outputs)\n",
        "        outputs = self.dropout_3(outputs, training)\n",
        "        outputs = self.norm_3(outputs + attention_2)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpzdiWHiwywF"
      },
      "source": [
        "class Decoder(layers.Layer):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"decoder\"):\n",
        "        super(Decoder, self).__init__(name=name)\n",
        "        self.d_model = d_model\n",
        "        self.nb_layers = nb_layers\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        \n",
        "        self.dec_layers = [DecoderLayer(FFN_units,\n",
        "                                        nb_proj,\n",
        "                                        dropout_rate) \n",
        "                           for i in range(nb_layers)]\n",
        "    \n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "        outputs = self.embedding(inputs)\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        \n",
        "        for i in range(self.nb_layers):\n",
        "            outputs = self.dec_layers[i](outputs,\n",
        "                                         enc_outputs,\n",
        "                                         mask_1,\n",
        "                                         mask_2,\n",
        "                                         training)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5sJYkjbz5DD"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqvqNjJPwyh-"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocab_size_enc,\n",
        "                 vocab_size_dec,\n",
        "                 d_model,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 name=\"transformer\"):\n",
        "        super(Transformer, self).__init__(name=name)\n",
        "        \n",
        "        self.encoder = Encoder(nb_layers,\n",
        "                               FFN_units,\n",
        "                               nb_proj,\n",
        "                               dropout_rate,\n",
        "                               vocab_size_enc,\n",
        "                               d_model)\n",
        "        self.decoder = Decoder(nb_layers,\n",
        "                               FFN_units,\n",
        "                               nb_proj,\n",
        "                               dropout_rate,\n",
        "                               vocab_size_dec,\n",
        "                               d_model)\n",
        "        self.last_linear = layers.Dense(units=vocab_size_dec, name=\"lin_ouput\")\n",
        "    \n",
        "    def create_padding_mask(self, seq):\n",
        "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    def create_look_ahead_mask(self, seq):\n",
        "        seq_len = tf.shape(seq)[1]\n",
        "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "        return look_ahead_mask\n",
        "    \n",
        "    def call(self, enc_inputs, dec_inputs, training):\n",
        "        enc_mask = self.create_padding_mask(enc_inputs)\n",
        "        dec_mask_1 = tf.maximum(\n",
        "            self.create_padding_mask(dec_inputs),\n",
        "            self.create_look_ahead_mask(dec_inputs)\n",
        "        )\n",
        "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
        "        \n",
        "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
        "        dec_outputs = self.decoder(dec_inputs,\n",
        "                                   enc_outputs,\n",
        "                                   dec_mask_1,\n",
        "                                   dec_mask_2,\n",
        "                                   training)\n",
        "        \n",
        "        outputs = self.last_linear(dec_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c-LRThUPrso"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiOdqQ5qPs8z"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "D_MODEL = 128 # 512\n",
        "NB_LAYERS = 4 # 6\n",
        "FFN_UNITS = 512 # 2048\n",
        "NB_PROJ = 8 # 8\n",
        "DROPOUT_RATE = 0.1 # 0.1\n",
        "\n",
        "transformer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n",
        "                          vocab_size_dec=VOCAB_SIZE_FR,\n",
        "                          d_model=D_MODEL,\n",
        "                          nb_layers=NB_LAYERS,\n",
        "                          FFN_units=FFN_UNITS,\n",
        "                          nb_proj=NB_PROJ,\n",
        "                          dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46xg4Wrg1Wgl"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction=\"none\")\n",
        "\n",
        "def loss_function(target, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
        "    loss_ = loss_object(target, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Goque362343"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        \n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "        \n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "leaning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb_32PIU5Zkh"
      },
      "source": [
        "checkpoint_path = \"./drive/My Drive/projects/transformer/ckpt/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhFK5kUx602K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f129b1-272a-4477-f4a7-cdaecb3e32bd"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Start of epoch {}\".format(epoch+1))\n",
        "    start = time.time()\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    \n",
        "    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
        "        dec_inputs = targets[:, :-1]\n",
        "        dec_outputs_real = targets[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = transformer(enc_inputs, dec_inputs, True)\n",
        "            loss = loss_function(dec_outputs_real, predictions)\n",
        "        \n",
        "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "        \n",
        "        train_loss(loss)\n",
        "        train_accuracy(dec_outputs_real, predictions)\n",
        "        \n",
        "        if batch % 50 == 0:\n",
        "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "                epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "            \n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(\"Saving checkpoint for epoch {} at {}\".format(epoch+1,\n",
        "                                                        ckpt_save_path))\n",
        "    print(\"Time taken for 1 epoch: {} secs\\n\".format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 1\n",
            "Epoch 1 Batch 0 Loss 6.7192 Accuracy 0.0526\n",
            "Epoch 1 Batch 50 Loss 6.1321 Accuracy 0.0526\n",
            "Epoch 1 Batch 100 Loss 6.0608 Accuracy 0.0516\n",
            "Epoch 1 Batch 150 Loss 5.9582 Accuracy 0.0513\n",
            "Epoch 1 Batch 200 Loss 5.8474 Accuracy 0.0563\n",
            "Epoch 1 Batch 250 Loss 5.7174 Accuracy 0.0634\n",
            "Epoch 1 Batch 300 Loss 5.5765 Accuracy 0.0683\n",
            "Epoch 1 Batch 350 Loss 5.4469 Accuracy 0.0720\n",
            "Epoch 1 Batch 400 Loss 5.3246 Accuracy 0.0748\n",
            "Epoch 1 Batch 450 Loss 5.2154 Accuracy 0.0781\n",
            "Epoch 1 Batch 500 Loss 5.1109 Accuracy 0.0825\n",
            "Epoch 1 Batch 550 Loss 5.0116 Accuracy 0.0875\n",
            "Epoch 1 Batch 600 Loss 4.9198 Accuracy 0.0924\n",
            "Epoch 1 Batch 650 Loss 4.8329 Accuracy 0.0973\n",
            "Epoch 1 Batch 700 Loss 4.7510 Accuracy 0.1024\n",
            "Epoch 1 Batch 750 Loss 4.6708 Accuracy 0.1075\n",
            "Epoch 1 Batch 800 Loss 4.5965 Accuracy 0.1124\n",
            "Epoch 1 Batch 850 Loss 4.5269 Accuracy 0.1172\n",
            "Epoch 1 Batch 900 Loss 4.4594 Accuracy 0.1217\n",
            "Epoch 1 Batch 950 Loss 4.3942 Accuracy 0.1262\n",
            "Epoch 1 Batch 1000 Loss 4.3326 Accuracy 0.1302\n",
            "Epoch 1 Batch 1050 Loss 4.2757 Accuracy 0.1343\n",
            "Epoch 1 Batch 1100 Loss 4.2242 Accuracy 0.1378\n",
            "Epoch 1 Batch 1150 Loss 4.1748 Accuracy 0.1411\n",
            "Epoch 1 Batch 1200 Loss 4.1279 Accuracy 0.1442\n",
            "Epoch 1 Batch 1250 Loss 4.0830 Accuracy 0.1473\n",
            "Epoch 1 Batch 1300 Loss 4.0391 Accuracy 0.1503\n",
            "Epoch 1 Batch 1350 Loss 3.9993 Accuracy 0.1533\n",
            "Epoch 1 Batch 1400 Loss 3.9606 Accuracy 0.1563\n",
            "Epoch 1 Batch 1450 Loss 3.9243 Accuracy 0.1591\n",
            "Epoch 1 Batch 1500 Loss 3.8860 Accuracy 0.1620\n",
            "Epoch 1 Batch 1550 Loss 3.8509 Accuracy 0.1648\n",
            "Epoch 1 Batch 1600 Loss 3.8197 Accuracy 0.1676\n",
            "Epoch 1 Batch 1650 Loss 3.7865 Accuracy 0.1703\n",
            "Epoch 1 Batch 1700 Loss 3.7532 Accuracy 0.1729\n",
            "Epoch 1 Batch 1750 Loss 3.7239 Accuracy 0.1755\n",
            "Epoch 1 Batch 1800 Loss 3.6960 Accuracy 0.1779\n",
            "Epoch 1 Batch 1850 Loss 3.6681 Accuracy 0.1803\n",
            "Epoch 1 Batch 1900 Loss 3.6412 Accuracy 0.1827\n",
            "Epoch 1 Batch 1950 Loss 3.6153 Accuracy 0.1850\n",
            "Epoch 1 Batch 2000 Loss 3.5899 Accuracy 0.1872\n",
            "Epoch 1 Batch 2050 Loss 3.5656 Accuracy 0.1892\n",
            "Epoch 1 Batch 2100 Loss 3.5413 Accuracy 0.1910\n",
            "Epoch 1 Batch 2150 Loss 3.5162 Accuracy 0.1928\n",
            "Epoch 1 Batch 2200 Loss 3.4916 Accuracy 0.1946\n",
            "Epoch 1 Batch 2250 Loss 3.4674 Accuracy 0.1962\n",
            "Epoch 1 Batch 2300 Loss 3.4443 Accuracy 0.1980\n",
            "Epoch 1 Batch 2350 Loss 3.4219 Accuracy 0.1997\n",
            "Epoch 1 Batch 2400 Loss 3.3993 Accuracy 0.2013\n",
            "Epoch 1 Batch 2450 Loss 3.3768 Accuracy 0.2031\n",
            "Epoch 1 Batch 2500 Loss 3.3555 Accuracy 0.2048\n",
            "Epoch 1 Batch 2550 Loss 3.3341 Accuracy 0.2066\n",
            "Epoch 1 Batch 2600 Loss 3.3130 Accuracy 0.2084\n",
            "Epoch 1 Batch 2650 Loss 3.2925 Accuracy 0.2102\n",
            "Epoch 1 Batch 2700 Loss 3.2718 Accuracy 0.2120\n",
            "Epoch 1 Batch 2750 Loss 3.2519 Accuracy 0.2138\n",
            "Epoch 1 Batch 2800 Loss 3.2329 Accuracy 0.2155\n",
            "Epoch 1 Batch 2850 Loss 3.2140 Accuracy 0.2173\n",
            "Epoch 1 Batch 2900 Loss 3.1954 Accuracy 0.2191\n",
            "Epoch 1 Batch 2950 Loss 3.1769 Accuracy 0.2208\n",
            "Epoch 1 Batch 3000 Loss 3.1588 Accuracy 0.2225\n",
            "Epoch 1 Batch 3050 Loss 3.1410 Accuracy 0.2242\n",
            "Epoch 1 Batch 3100 Loss 3.1232 Accuracy 0.2258\n",
            "Epoch 1 Batch 3150 Loss 3.1059 Accuracy 0.2275\n",
            "Epoch 1 Batch 3200 Loss 3.0892 Accuracy 0.2292\n",
            "Epoch 1 Batch 3250 Loss 3.0721 Accuracy 0.2308\n",
            "Epoch 1 Batch 3300 Loss 3.0552 Accuracy 0.2325\n",
            "Epoch 1 Batch 3350 Loss 3.0387 Accuracy 0.2342\n",
            "Epoch 1 Batch 3400 Loss 3.0226 Accuracy 0.2359\n",
            "Epoch 1 Batch 3450 Loss 3.0065 Accuracy 0.2376\n",
            "Epoch 1 Batch 3500 Loss 2.9907 Accuracy 0.2392\n",
            "Epoch 1 Batch 3550 Loss 2.9754 Accuracy 0.2409\n",
            "Epoch 1 Batch 3600 Loss 2.9597 Accuracy 0.2426\n",
            "Epoch 1 Batch 3650 Loss 2.9450 Accuracy 0.2442\n",
            "Epoch 1 Batch 3700 Loss 2.9299 Accuracy 0.2459\n",
            "Epoch 1 Batch 3750 Loss 2.9147 Accuracy 0.2476\n",
            "Epoch 1 Batch 3800 Loss 2.9003 Accuracy 0.2492\n",
            "Epoch 1 Batch 3850 Loss 2.8864 Accuracy 0.2508\n",
            "Epoch 1 Batch 3900 Loss 2.8724 Accuracy 0.2524\n",
            "Epoch 1 Batch 3950 Loss 2.8589 Accuracy 0.2540\n",
            "Epoch 1 Batch 4000 Loss 2.8456 Accuracy 0.2556\n",
            "Epoch 1 Batch 4050 Loss 2.8321 Accuracy 0.2571\n",
            "Epoch 1 Batch 4100 Loss 2.8191 Accuracy 0.2587\n",
            "Epoch 1 Batch 4150 Loss 2.8069 Accuracy 0.2601\n",
            "Epoch 1 Batch 4200 Loss 2.7958 Accuracy 0.2614\n",
            "Epoch 1 Batch 4250 Loss 2.7843 Accuracy 0.2627\n",
            "Epoch 1 Batch 4300 Loss 2.7735 Accuracy 0.2639\n",
            "Epoch 1 Batch 4350 Loss 2.7630 Accuracy 0.2651\n",
            "Epoch 1 Batch 4400 Loss 2.7529 Accuracy 0.2662\n",
            "Epoch 1 Batch 4450 Loss 2.7433 Accuracy 0.2673\n",
            "Epoch 1 Batch 4500 Loss 2.7334 Accuracy 0.2684\n",
            "Epoch 1 Batch 4550 Loss 2.7235 Accuracy 0.2694\n",
            "Epoch 1 Batch 4600 Loss 2.7139 Accuracy 0.2705\n",
            "Epoch 1 Batch 4650 Loss 2.7044 Accuracy 0.2715\n",
            "Epoch 1 Batch 4700 Loss 2.6952 Accuracy 0.2726\n",
            "Epoch 1 Batch 4750 Loss 2.6861 Accuracy 0.2736\n",
            "Epoch 1 Batch 4800 Loss 2.6766 Accuracy 0.2746\n",
            "Epoch 1 Batch 4850 Loss 2.6678 Accuracy 0.2756\n",
            "Epoch 1 Batch 4900 Loss 2.6593 Accuracy 0.2766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmzyRwDrRGdq"
      },
      "source": [
        "# Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNHwJJrz3lPB"
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "    inp_sentence = \\\n",
        "        [VOCAB_SIZE_EN-2] + tokenizer_en.encode(inp_sentence) + [VOCAB_SIZE_EN-1]\n",
        "    enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
        "    \n",
        "    output = tf.expand_dims([VOCAB_SIZE_FR-2], axis=0)\n",
        "    \n",
        "    for _ in range(MAX_LENGTH):\n",
        "        predictions = transformer(enc_input, output, False)\n",
        "        \n",
        "        prediction = predictions[:, -1:, :]\n",
        "        \n",
        "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
        "        \n",
        "        if predicted_id == VOCAB_SIZE_FR-1:\n",
        "            return tf.squeeze(output, axis=0)\n",
        "        \n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "        \n",
        "    return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6VeFKrE6Kdx"
      },
      "source": [
        "def translate(sentence):\n",
        "    output = evaluate(sentence).numpy()\n",
        "    \n",
        "    predicted_sentence = tokenizer_fr.decode(\n",
        "        [i for i in output if i < VOCAB_SIZE_FR-2]\n",
        "    )\n",
        "    \n",
        "    print(\"Input: {}\".format(sentence))\n",
        "    print(\"Predicted translation: {}\".format(predicted_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoWKbCP7Czs"
      },
      "source": [
        "translate(\"This is a really powerful tool!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}