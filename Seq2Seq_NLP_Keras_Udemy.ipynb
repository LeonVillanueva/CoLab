{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq NLP Keras Udemy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrZ7WKhJmk7WRsHjHGp+OY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonVillanueva/CoLab/blob/master/Seq2Seq_NLP_Keras_Udemy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjvsUwjDlD_x"
      },
      "source": [
        "# # https://deeplearningcourses.com/c/deep-learning-advanced-nlp\r\n",
        "# get the data at: http://www.manythings.org/anki/\r\n",
        "from __future__ import print_function, division\r\n",
        "from builtins import range, input\r\n",
        "# Note: you may need to update your version of future\r\n",
        "# sudo pip install -U future\r\n",
        "\r\n",
        "import os, sys\r\n",
        "\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "try:\r\n",
        "  import keras.backend as K\r\n",
        "  if len(K.tensorflow_backend._get_available_gpus()) > 0:\r\n",
        "    from keras.layers import CuDNNLSTM as LSTM\r\n",
        "    from keras.layers import CuDNNGRU as GRU\r\n",
        "except:\r\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckbt1SYslWd6"
      },
      "source": [
        "BATCH_SIZE = 64  # Batch size for training.\r\n",
        "EPOCHS = 40  # Number of epochs to train for.\r\n",
        "LATENT_DIM = 256  # Latent dimensionality of the encoding space.\r\n",
        "NUM_SAMPLES = 10000  # Number of samples to train on.\r\n",
        "MAX_NUM_WORDS = 20000\r\n",
        "EMBEDDING_DIM = 50\r\n",
        "\r\n",
        "# Where we will store the data\r\n",
        "input_texts = [] # sentence in original language\r\n",
        "target_texts = [] # sentence in target language\r\n",
        "target_texts_inputs = [] # sentence in target language offset by 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yHizSRzlbJa",
        "outputId": "71c49324-9279-49c5-805a-d6684b0e8305"
      },
      "source": [
        "t = 0\r\n",
        "for line in open('sample_data/spa.txt'):\r\n",
        "  # only keep a limited number of samples\r\n",
        "  t += 1\r\n",
        "  if t > NUM_SAMPLES:\r\n",
        "    break\r\n",
        "\r\n",
        "  # input and target are separated by tab\r\n",
        "  if '\\t' not in line:\r\n",
        "    continue\r\n",
        "\r\n",
        "  # split up the input and translation\r\n",
        "  input_text, translation, *rest = line.rstrip().split('\\t')\r\n",
        "\r\n",
        "  # make the target input and output\r\n",
        "  # recall we'll be using teacher forcing\r\n",
        "  target_text = translation + ' <eos>'\r\n",
        "  target_text_input = '<sos> ' + translation\r\n",
        "\r\n",
        "  input_texts.append(input_text)\r\n",
        "  target_texts.append(target_text)\r\n",
        "  target_texts_inputs.append(target_text_input)\r\n",
        "print(\"num samples:\", len(input_texts))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeHT5xIcnjAS",
        "outputId": "b6e9b405-a554-4c69-b2e9-ef669d0e002f"
      },
      "source": [
        "# tokenize the inputs\r\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\r\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\r\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\r\n",
        "\r\n",
        "# get the word to index mapping for input language\r\n",
        "word2idx_inputs = tokenizer_inputs.word_index\r\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2355 unique input tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5Yia-_hno_u"
      },
      "source": [
        "# determine maximum length input sequence\r\n",
        "max_len_input = max(len(s) for s in input_sequences)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZl_4g-YntE8"
      },
      "source": [
        "# tokenize the outputs\r\n",
        "# don't filter out special characters\r\n",
        "# otherwise <sos> and <eos> won't appear\r\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\r\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\r\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\r\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5kLHlJooEvt",
        "outputId": "29d1a0ea-570a-4894-96a6-dffbb118b8b8"
      },
      "source": [
        "# get the word to index mapping for output language\r\n",
        "word2idx_outputs = tokenizer_outputs.word_index\r\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\r\n",
        "\r\n",
        "# store number of output words for later\r\n",
        "# remember to add 1 since indexing starts at 1\r\n",
        "num_words_output = len(word2idx_outputs) + 1\r\n",
        "\r\n",
        "# determine maximum length output sequence\r\n",
        "max_len_target = max(len(s) for s in target_sequences)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6335 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GVM4y9coF41",
        "outputId": "a3a9819d-2a08-45ae-d98b-b94f5cbb56c7"
      },
      "source": [
        "# pad the sequences\r\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\r\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\r\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\r\n",
        "\r\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\r\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\r\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\r\n",
        "\r\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (10000, 5)\n",
            "encoder_inputs[0]: [ 0  0  0  0 12]\n",
            "decoder_inputs[0]: [   2 1463    0    0    0    0    0    0    0]\n",
            "decoder_inputs.shape: (10000, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKW5L334oJu9",
        "outputId": "73e0d6a1-4e7a-4104-ce0a-1396107dcbc7"
      },
      "source": [
        "# store all the pre-trained word vectors\r\n",
        "print('Loading word vectors...')\r\n",
        "word2vec = {}\r\n",
        "with open(os.path.join('sample_data/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\r\n",
        "  # is just a space-separated text file in the format:\r\n",
        "  # word vec[0] vec[1] vec[2] ...\r\n",
        "  for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    vec = np.asarray(values[1:], dtype='float32')\r\n",
        "    word2vec[word] = vec\r\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8mPz_kJtDQ5",
        "outputId": "5f4e78da-5523-4317-9e4d-e7b468a00e0f"
      },
      "source": [
        "# prepare embedding matrix\r\n",
        "print('Filling pre-trained embeddings...')\r\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\r\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\r\n",
        "for word, i in word2idx_inputs.items():\r\n",
        "  if i < MAX_NUM_WORDS:\r\n",
        "    embedding_vector = word2vec.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "      # words not found in embedding index will be all zeros.\r\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv6i-KKwtQe9"
      },
      "source": [
        "# create embedding layer\r\n",
        "embedding_layer = Embedding(\r\n",
        "  num_words,\r\n",
        "  EMBEDDING_DIM,\r\n",
        "  weights=[embedding_matrix],\r\n",
        "  input_length=max_len_input,\r\n",
        "  # trainable=True\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "# create targets, since we cannot use sparse\r\n",
        "# categorical cross entropy when we have sequences\r\n",
        "decoder_targets_one_hot = np.zeros(\r\n",
        "  (\r\n",
        "    len(input_texts),\r\n",
        "    max_len_target,\r\n",
        "    num_words_output\r\n",
        "  ),\r\n",
        "  dtype='float32'\r\n",
        ")\r\n",
        "\r\n",
        "# assign the values\r\n",
        "for i, d in enumerate(decoder_targets):\r\n",
        "  for t, word in enumerate(d):\r\n",
        "    if word != 0:\r\n",
        "      decoder_targets_one_hot[i, t, word] = 1\r\n",
        "\r\n",
        "##### build the model #####\r\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\r\n",
        "x = embedding_layer(encoder_inputs_placeholder)\r\n",
        "encoder = LSTM(\r\n",
        "  LATENT_DIM,\r\n",
        "  return_state=True,\r\n",
        "  # dropout=0.5 # dropout not available on gpu\r\n",
        ")\r\n",
        "encoder_outputs, h, c = encoder(x)\r\n",
        "# encoder_outputs, h = encoder(x) #gru\r\n",
        "\r\n",
        "# keep only the states to pass into decoder\r\n",
        "encoder_states = [h, c]\r\n",
        "# encoder_states = [state_h] # gru\r\n",
        "\r\n",
        "# Set up the decoder, using [h, c] as initial state.\r\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\r\n",
        "\r\n",
        "# this word embedding will not use pre-trained vectors\r\n",
        "# although you could\r\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\r\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\r\n",
        "\r\n",
        "# since the decoder is a \"to-many\" model we want to have\r\n",
        "# return_sequences=True\r\n",
        "decoder_lstm = LSTM(\r\n",
        "  LATENT_DIM,\r\n",
        "  return_sequences=True,\r\n",
        "  return_state=True,\r\n",
        "  # dropout=0.5 # dropout not available on gpu\r\n",
        ")\r\n",
        "decoder_outputs, _, _ = decoder_lstm(\r\n",
        "  decoder_inputs_x,\r\n",
        "  initial_state=encoder_states\r\n",
        ")\r\n",
        "\r\n",
        "# decoder_outputs, _ = decoder_gru(\r\n",
        "#   decoder_inputs_x,\r\n",
        "#   initial_state=encoder_states\r\n",
        "# )\r\n",
        "\r\n",
        "# final dense layer for predictions\r\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "\r\n",
        "# Create the model object\r\n",
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UErU8by6xJBf"
      },
      "source": [
        "def custom_loss(y_true, y_pred):\r\n",
        "  # both are of shape N x T x K\r\n",
        "  mask = K.cast(y_true > 0, dtype='float32')\r\n",
        "  out = mask * y_true * K.log(y_pred)\r\n",
        "  return -K.sum(out) / K.sum(mask)\r\n",
        "\r\n",
        "\r\n",
        "def acc(y_true, y_pred):\r\n",
        "  # both are of shape N x T x K\r\n",
        "  targ = K.argmax(y_true, axis=-1)\r\n",
        "  pred = K.argmax(y_pred, axis=-1)\r\n",
        "  correct = K.cast(K.equal(targ, pred), dtype='float32')\r\n",
        "\r\n",
        "  # 0 is padding, don't include those\r\n",
        "  mask = K.cast(K.greater(targ, 0), dtype='float32')\r\n",
        "  n_correct = K.sum(mask * correct)\r\n",
        "  n_total = K.sum(mask)\r\n",
        "  return n_correct / n_total\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\r\n",
        "\r\n",
        "# Compile the model and train it\r\n",
        "# model.compile(\r\n",
        "#   optimizer='rmsprop',\r\n",
        "#   loss='categorical_crossentropy',\r\n",
        "#   metrics=['accuracy']\r\n",
        "# )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q2BqugXlxOqI",
        "outputId": "fb3a4fee-4412-4542-be36-076235f65d78"
      },
      "source": [
        "r = model.fit(\r\n",
        "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\r\n",
        "  batch_size=BATCH_SIZE,\r\n",
        "  epochs=EPOCHS,\r\n",
        "  validation_split=0.2,\r\n",
        ")\r\n",
        "\r\n",
        "# plot some data\r\n",
        "plt.plot(r.history['loss'], label='loss')\r\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# accuracies\r\n",
        "plt.plot(r.history['accuracy'], label='acc')\r\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Save model\r\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "125/125 [==============================] - 36s 261ms/step - loss: 6.7234 - acc: 0.2600 - val_loss: 5.6015 - val_acc: 0.2715\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 5.0409 - acc: 0.2942 - val_loss: 5.3314 - val_acc: 0.2844\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 4.6637 - acc: 0.3110 - val_loss: 5.1845 - val_acc: 0.3070\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 31s 250ms/step - loss: 4.3536 - acc: 0.3343 - val_loss: 5.0373 - val_acc: 0.3220\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 4.0663 - acc: 0.3559 - val_loss: 4.9126 - val_acc: 0.3489\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 31s 252ms/step - loss: 3.7903 - acc: 0.3883 - val_loss: 4.8127 - val_acc: 0.3687\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 3.5536 - acc: 0.4141 - val_loss: 4.7609 - val_acc: 0.3884\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 3.3172 - acc: 0.4343 - val_loss: 4.7123 - val_acc: 0.3971\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 32s 253ms/step - loss: 3.1112 - acc: 0.4522 - val_loss: 4.6734 - val_acc: 0.4035\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 32s 257ms/step - loss: 2.9128 - acc: 0.4709 - val_loss: 4.6695 - val_acc: 0.4108\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 2.7285 - acc: 0.4904 - val_loss: 4.6356 - val_acc: 0.4220\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 2.5522 - acc: 0.5121 - val_loss: 4.6481 - val_acc: 0.4262\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 2.3820 - acc: 0.5282 - val_loss: 4.6426 - val_acc: 0.4303\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 32s 253ms/step - loss: 2.2013 - acc: 0.5505 - val_loss: 4.6330 - val_acc: 0.4332\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 2.0535 - acc: 0.5698 - val_loss: 4.6463 - val_acc: 0.4360\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 1.8941 - acc: 0.5930 - val_loss: 4.6503 - val_acc: 0.4309\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 31s 252ms/step - loss: 1.7694 - acc: 0.6155 - val_loss: 4.6621 - val_acc: 0.4370\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 1.6324 - acc: 0.6396 - val_loss: 4.6720 - val_acc: 0.4371\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 1.5097 - acc: 0.6646 - val_loss: 4.6870 - val_acc: 0.4344\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 1.3911 - acc: 0.6849 - val_loss: 4.7110 - val_acc: 0.4334\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 1.2913 - acc: 0.7057 - val_loss: 4.7319 - val_acc: 0.4309\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 32s 253ms/step - loss: 1.1967 - acc: 0.7230 - val_loss: 4.7499 - val_acc: 0.4285\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 1.1179 - acc: 0.7421 - val_loss: 4.7795 - val_acc: 0.4232\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 1.0294 - acc: 0.7619 - val_loss: 4.8077 - val_acc: 0.4237\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 32s 258ms/step - loss: 0.9691 - acc: 0.7709 - val_loss: 4.8219 - val_acc: 0.4241\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 0.8924 - acc: 0.7890 - val_loss: 4.8535 - val_acc: 0.4202\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 31s 250ms/step - loss: 0.8399 - acc: 0.8013 - val_loss: 4.8655 - val_acc: 0.4192\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 32s 253ms/step - loss: 0.7829 - acc: 0.8114 - val_loss: 4.8824 - val_acc: 0.4203\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 0.7326 - acc: 0.8199 - val_loss: 4.9211 - val_acc: 0.4195\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 32s 254ms/step - loss: 0.6850 - acc: 0.8270 - val_loss: 4.9468 - val_acc: 0.4178\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 32s 253ms/step - loss: 0.6412 - acc: 0.8404 - val_loss: 4.9605 - val_acc: 0.4180\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 0.6032 - acc: 0.8483 - val_loss: 4.9762 - val_acc: 0.4201\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 32s 257ms/step - loss: 0.5678 - acc: 0.8525 - val_loss: 5.0023 - val_acc: 0.4156\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 0.5333 - acc: 0.8596 - val_loss: 5.0136 - val_acc: 0.4154\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 32s 253ms/step - loss: 0.5034 - acc: 0.8660 - val_loss: 5.0368 - val_acc: 0.4163\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 32s 252ms/step - loss: 0.4768 - acc: 0.8703 - val_loss: 5.0757 - val_acc: 0.4108\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 0.4519 - acc: 0.8750 - val_loss: 5.0550 - val_acc: 0.4198\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 32s 257ms/step - loss: 0.4349 - acc: 0.8754 - val_loss: 5.1099 - val_acc: 0.4086\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 32s 255ms/step - loss: 0.4067 - acc: 0.8807 - val_loss: 5.1277 - val_acc: 0.4155\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 0.3981 - acc: 0.8814 - val_loss: 5.1532 - val_acc: 0.4086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2e38b4b3fe92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRPg21yVxUTI",
        "outputId": "de00e904-f327-4e38-b7df-5e1513f4adc1"
      },
      "source": [
        "##### Make predictions #####\r\n",
        "# As with the poetry example, we need to create another model\r\n",
        "# that can take in the RNN state and previous word as input\r\n",
        "# and accept a T=1 sequence.\r\n",
        "\r\n",
        "# The encoder will be stand-alone\r\n",
        "# From this we will get our initial decoder hidden state\r\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\r\n",
        "\r\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\r\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\r\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "# decoder_states_inputs = [decoder_state_input_h] # gru\r\n",
        "\r\n",
        "decoder_inputs_single = Input(shape=(1,))\r\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\r\n",
        "\r\n",
        "# this time, we want to keep the states too, to be output\r\n",
        "# by our sampling model\r\n",
        "decoder_outputs, h, c = decoder_lstm(\r\n",
        "  decoder_inputs_single_x,\r\n",
        "  initial_state=decoder_states_inputs\r\n",
        ")\r\n",
        "# decoder_outputs, state_h = decoder_lstm(\r\n",
        "#   decoder_inputs_single_x,\r\n",
        "#   initial_state=decoder_states_inputs\r\n",
        "# ) #gru\r\n",
        "decoder_states = [h, c]\r\n",
        "# decoder_states = [h] # gru\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "\r\n",
        "# The sampling model\r\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\r\n",
        "# outputs: y(t), h(t), c(t)\r\n",
        "decoder_model = Model(\r\n",
        "  [decoder_inputs_single] + decoder_states_inputs, \r\n",
        "  [decoder_outputs] + decoder_states\r\n",
        ")\r\n",
        "\r\n",
        "# map indexes back into real words\r\n",
        "# so we can view the results\r\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\r\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\r\n",
        "\r\n",
        "\r\n",
        "def decode_sequence(input_seq):\r\n",
        "  # Encode the input as state vectors.\r\n",
        "  states_value = encoder_model.predict(input_seq)\r\n",
        "\r\n",
        "  # Generate empty target sequence of length 1.\r\n",
        "  target_seq = np.zeros((1, 1))\r\n",
        "\r\n",
        "  # Populate the first character of target sequence with the start character.\r\n",
        "  # NOTE: tokenizer lower-cases all words\r\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\r\n",
        "\r\n",
        "  # if we get this we break\r\n",
        "  eos = word2idx_outputs['<eos>']\r\n",
        "\r\n",
        "  # Create the translation\r\n",
        "  output_sentence = []\r\n",
        "  for _ in range(max_len_target):\r\n",
        "    output_tokens, h, c = decoder_model.predict(\r\n",
        "      [target_seq] + states_value\r\n",
        "    )\r\n",
        "    # output_tokens, h = decoder_model.predict(\r\n",
        "    #     [target_seq] + states_value\r\n",
        "    # ) # gru\r\n",
        "\r\n",
        "    # Get next word\r\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\r\n",
        "\r\n",
        "    # End sentence of EOS\r\n",
        "    if eos == idx:\r\n",
        "      break\r\n",
        "\r\n",
        "    word = ''\r\n",
        "    if idx > 0:\r\n",
        "      word = idx2word_trans[idx]\r\n",
        "      output_sentence.append(word)\r\n",
        "\r\n",
        "    # Update the decoder input\r\n",
        "    # which is just the word just generated\r\n",
        "    target_seq[0, 0] = idx\r\n",
        "\r\n",
        "    # Update states\r\n",
        "    states_value = [h, c]\r\n",
        "    # states_value = [h] # gru\r\n",
        "\r\n",
        "  return ' '.join(output_sentence)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "while True:\r\n",
        "  # Do some test translations\r\n",
        "  i = np.random.choice(len(input_texts))\r\n",
        "  input_seq = encoder_inputs[i:i+1]\r\n",
        "  translation = decode_sequence(input_seq)\r\n",
        "  print('-')\r\n",
        "  print('Input:', input_texts[i])\r\n",
        "  print('Translation:', translation)\r\n",
        "\r\n",
        "  ans = input(\"Continue? [Y/n]\")\r\n",
        "  if ans and ans.lower().startswith('n'):\r\n",
        "    break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: She isn't there.\n",
            "Translation: ella no está aquí.\n",
            "Continue? [Y/n]y\n",
            "-\n",
            "Input: Be a man.\n",
            "Translation: sé un hombre.\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}