{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"florante_laura_nlp.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO26RDnduhUXqUd7hqajdWu"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"MzfhyhbQA_xV","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import tensorflow.keras.utils as ku \n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWYFb3hbBJIb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"3143a426-a16a-4fec-f113-bde3cfe6f286","executionInfo":{"status":"error","timestamp":1592144255379,"user_tz":240,"elapsed":2269,"user":{"displayName":"Leon V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSU_p-jIsDCkhfJkvEGmAcTv7r909z5RnjuCf-qw=s64","userId":"16866923639547555592"}}},"source":["tokenizer = Tokenizer()\n","data = open('florante_laura.txt').read()"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-95fbbf4401c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'florante_laura.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'florante_laura.txt'"]}]},{"cell_type":"code","metadata":{"id":"Fles0-4FBleL","colab_type":"code","colab":{}},"source":["import re\n","data = re.sub('[.*?]', '', data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spRXS4WwBaB7","colab_type":"code","colab":{}},"source":["corpus = data.lower().split(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZO0bsiHCjzG","colab_type":"code","colab":{}},"source":["tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"un_OJMBrCmxV","colab_type":"code","colab":{}},"source":["input_sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tinput_sequences.append(n_gram_sequence)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LKbKZzkpC1hZ","colab_type":"code","colab":{}},"source":["# pad sequences \n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# create predictors and label\n","predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","\n","label = ku.to_categorical(label, num_classes=total_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKIVTz1ZC69e","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(150, return_sequences = True)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(100))\n","model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnnlY184C-1V","colab_type":"code","colab":{}},"source":["history = model.fit(predictors, label, epochs=100, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lcym8qnCEAbl","colab_type":"code","colab":{}},"source":["seed_text = \"sa gubat na madilim, na puno ng bulaclac\"\n","next_words = 50\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = model.predict_classes(token_list, verbose=0)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":0,"outputs":[]}]}